{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05274d4-de69-4ed4-8527-be0e607703e3",
   "metadata": {},
   "source": [
    "Include some system headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa265a92-efbb-43d5-afc0-6eaa02d3cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <vector>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70695a6e-c5ff-4227-bfb6-6f56ea08dea6",
   "metadata": {},
   "source": [
    "Read environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06939297-1dab-4f14-8d1a-46d5c39c5d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMOTIEFFLIB_ROOT: /home/echuraev/Workspace/HSE/face-emotion-recognition\n",
      "EMOTIEFFLIB_BUILD_DIR: /home/echuraev/Workspace/HSE/face-emotion-recognition/emotieffcpplib/build\n"
     ]
    }
   ],
   "source": [
    "const std::string emotiEffLibRootDir(std::getenv(\"EMOTIEFFLIB_ROOT\"));\n",
    "const std::string emotiEffLibBuildDir(std::getenv(\"EMOTIEFFLIB_BUILD_DIR\"));\n",
    "\n",
    "std::cout << \"EMOTIEFFLIB_ROOT: \" << emotiEffLibRootDir << std::endl;\n",
    "std::cout << \"EMOTIEFFLIB_BUILD_DIR: \" << emotiEffLibBuildDir << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe906e19-ef36-4f33-a3de-2cba488171f5",
   "metadata": {},
   "source": [
    "Add linking with necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddf5887d-320a-469b-96e5-053b5b814e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NOTE: It is important that all paths in pragma should be specified as a string constant.\n",
    "// Please, copy it from the output of the previous cell.\n",
    "\n",
    "// Path to EmotiEffCpp lib dependencies\n",
    "#pragma cling add_include_path(\"/home/echuraev/Workspace/HSE/face-emotion-recognition/emotieffcpplib/include\")\n",
    "#pragma cling add_include_path(\"/home/echuraev/Workspace/HSE/face-emotion-recognition/emotieffcpplib/3rdparty/opencv-mtcnn/lib/include\")\n",
    "#pragma cling add_include_path(\"/home/echuraev/Workspace/HSE/face-emotion-recognition/emotieffcpplib/3rdparty/xtensor/include\")\n",
    "// Path to OpenCV\n",
    "#pragma cling add_include_path(\"/usr/include/opencv4\")\n",
    "// Path to ONNXRuntime\n",
    "#pragma cling add_include_path(\"/home/echuraev/Workspace/HSE/onnxruntime/include\")\n",
    "// Path to Libtorch\n",
    "#pragma cling add_include_path(\"/home/echuraev/Workspace/HSE/libtorch/include\")\n",
    "\n",
    "#pragma cling add_library_path(\"/home/echuraev/Workspace/HSE/face-emotion-recognition/emotieffcpplib/build/lib\")\n",
    "#pragma cling load(\"emotiefflib\")\n",
    "#pragma cling load(\"mtcnn\")\n",
    "#pragma cling load(\"libopencv_shape\")\n",
    "#pragma cling load(\"libopencv_stitching\")\n",
    "#pragma cling load(\"libopencv_objdetect\")\n",
    "#pragma cling load(\"libopencv_superres\")\n",
    "#pragma cling load(\"libopencv_videostab\")\n",
    "#pragma cling load(\"libopencv_calib3d\")\n",
    "#pragma cling load(\"libopencv_features2d\")\n",
    "#pragma cling load(\"libopencv_highgui\")\n",
    "#pragma cling load(\"libopencv_videoio\")\n",
    "#pragma cling load(\"libopencv_imgcodecs\")\n",
    "#pragma cling load(\"libopencv_video\")\n",
    "#pragma cling load(\"libopencv_photo\")\n",
    "#pragma cling load(\"libopencv_ml\")\n",
    "#pragma cling load(\"libopencv_imgproc\")\n",
    "#pragma cling load(\"libopencv_dnn\")\n",
    "#pragma cling load(\"libopencv_viz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cef61-9aad-4eb6-8316-2207e0c1e493",
   "metadata": {},
   "source": [
    "Include necessary headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62271fe5-9934-4cfe-87e1-54d59fccd758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <emotiefflib/facial_analysis.h>\n",
    "#include <mtcnn/detector.h>\n",
    "\n",
    "#include <xtensor/xarray.hpp>\n",
    "#include <xtensor/xio.hpp>\n",
    "#include <xtensor/xmath.hpp>\n",
    "#include <xtensor/xsort.hpp>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a3446-5d65-417d-9e44-e760733e6853",
   "metadata": {},
   "source": [
    "To improve performance, we downscale the input image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fce69cf4-c643-4ecf-ab81-4412fc5b66e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv::Mat downscaleImageToWidth(const cv::Mat& inputImage, int targetWidth) {\n",
    "    // Get the original dimensions\n",
    "    int originalWidth = inputImage.cols;\n",
    "    int originalHeight = inputImage.rows;\n",
    "\n",
    "    if (originalWidth < targetWidth)\n",
    "        return inputImage;\n",
    "\n",
    "    // Calculate the scaling factor\n",
    "    double scaleFactor = static_cast<double>(targetWidth) / originalWidth;\n",
    "\n",
    "    // Calculate the new height while maintaining the aspect ratio\n",
    "    int targetHeight = static_cast<int>(originalHeight * scaleFactor);\n",
    "\n",
    "    // Resize the image\n",
    "    cv::Mat outputImage;\n",
    "    cv::resize(inputImage, outputImage, cv::Size(targetWidth, targetHeight));\n",
    "\n",
    "    return outputImage;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6382c31-6313-4788-82f5-d03953921a50",
   "metadata": {},
   "source": [
    "Function for faces recognition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b7f868-742c-4585-8d93-87b2b4432677",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::vector<cv::Mat> recognizeFaces(const cv::Mat& frame, int downscaleWidth) {\n",
    "    auto dirWithModels = emotiEffLibRootDir + \"/emotieffcpplib/3rdparty/opencv-mtcnn/data/models\";\n",
    "    ProposalNetwork::Config pConfig;\n",
    "    pConfig.protoText = dirWithModels + \"/det1.prototxt\";\n",
    "    pConfig.caffeModel = dirWithModels + \"/det1.caffemodel\";\n",
    "    pConfig.threshold = 0.6f;\n",
    "    RefineNetwork::Config rConfig;\n",
    "    rConfig.protoText = dirWithModels + \"/det2.prototxt\";\n",
    "    rConfig.caffeModel = dirWithModels + \"/det2.caffemodel\";\n",
    "    rConfig.threshold = 0.7f;\n",
    "    OutputNetwork::Config oConfig;\n",
    "    oConfig.protoText = dirWithModels + \"/det3.prototxt\";\n",
    "    oConfig.caffeModel = dirWithModels + \"/det3.caffemodel\";\n",
    "    oConfig.threshold = 0.7f;\n",
    "    MTCNNDetector detector(pConfig, rConfig, oConfig);\n",
    "    auto scaledFrame = downscaleImageToWidth(frame, downscaleWidth);\n",
    "    double downcastRatioW = static_cast<double>(frame.cols) / scaledFrame.cols;\n",
    "    double downcastRatioH = static_cast<double>(frame.rows) / scaledFrame.rows;\n",
    "    std::vector<Face> faces = detector.detect(scaledFrame, 20.f, 0.709f);\n",
    "    std::vector<cv::Mat> cvFaces = {};\n",
    "    cvFaces.reserve(faces.size());\n",
    "    for (auto& face : faces) {\n",
    "        face.bbox.x1 *= downcastRatioW;\n",
    "        face.bbox.x2 *= downcastRatioW;\n",
    "        face.bbox.y1 *= downcastRatioH;\n",
    "        face.bbox.y2 *= downcastRatioH;\n",
    "        cv::Rect roi(face.bbox.x1, face.bbox.y1, face.bbox.x2 - face.bbox.x1,\n",
    "                     face.bbox.y2 - face.bbox.y1);\n",
    "        cv::Mat f = frame(roi).clone();\n",
    "        cvFaces.push_back(f);\n",
    "    }\n",
    "    return cvFaces;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d30c046b-f8c6-447a-b499-b23df8e993aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "// std::string img2base64(const cv::Mat& img) {\n",
    "//     std::vector<uchar> buf;\n",
    "//     cv::imencode(\".jpg\", img, buf);\n",
    "//     auto *enc_msg = reinterpret_cast<unsigned char*>(buf.data());\n",
    "//     std::string encoded = base64_encode(enc_msg, buf.size());\n",
    "//     return encoded;\n",
    "// }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71de426-2c23-4a38-a22c-cc60154ea8a8",
   "metadata": {},
   "source": [
    "Open test image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a76300-2827-4205-bb8b-239d3af17a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto imagePath = emotiEffLibRootDir + \"/tests/test_images/20180720_174416.jpg\";\n",
    "cv::Mat frame = cv::imread(imagePath);\n",
    "cv::Mat frameRgb;\n",
    "cv::cvtColor(frame, frameRgb, cv::COLOR_BGR2RGB);\n",
    "//cv::imshow(\"Image\", frameRgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0672919-012c-40d4-9a28-091ed0a23ddf",
   "metadata": {},
   "source": [
    "Recognize faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f816658-e000-4c87-8e56-356fb9597c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anger == Anger\n",
      "Happiness == Happiness\n",
      "Happiness == Happiness\n"
     ]
    }
   ],
   "source": [
    "auto facialImages = recognizeFaces(frame, 500);\n",
    "std::string modelPath = emotiEffLibRootDir + \"/models/emotieffcpplib_prepared_models/enet_b0_8_best_afew.onnx\";\n",
    "std::string backend = \"onnx\";\n",
    "auto fer = EmotiEffLib::EmotiEffLibRecognizer::createInstance(backend, modelPath);\n",
    "for (auto& face : facialImages) {\n",
    "    auto res = fer->predictEmotions(face, true);\n",
    "    auto pred = xt::argmax(res.scores, 1);\n",
    "    std::cout << res.labels[0] << \" == \" << fer->getEmotionClassById(pred[0]) << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000f98a-f6b9-40ef-985c-e81d50ad6206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++17",
   "language": "C++17",
   "name": "xcpp17"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
